diff -Nur glibc-ports-2.5-orig/sysdeps/unix/sysv/linux/arm/nptl/bits/atomic.h glibc-ports-2.5/sysdeps/unix/sysv/linux/arm/nptl/bits/atomic.h
--- glibc-ports-2.5-orig/sysdeps/unix/sysv/linux/arm/nptl/bits/atomic.h	2022-06-01 01:16:09.314800460 +0200
+++ glibc-ports-2.5/sysdeps/unix/sysv/linux/arm/nptl/bits/atomic.h	2022-06-01 01:16:58.281446457 +0200
@@ -37,22 +37,20 @@
 
 void __arm_link_error (void);
 
-#define atomic_exchange_acq(mem, newvalue)				      \
-  ({ __typeof (*mem) result;						      \
-     if (sizeof (*mem) == 1)						      \
-       __asm__ __volatile__ ("swpb %0, %1, [%2]"			      \
-			     : "=&r,&r" (result)			      \
-			     : "r,0" (newvalue), "r,r" (mem) : "memory");     \
-     else if (sizeof (*mem) == 4)					      \
-       __asm__ __volatile__ ("swp %0, %1, [%2]"				      \
-			     : "=&r,&r" (result)			      \
-			     : "r,0" (newvalue), "r,r" (mem) : "memory");     \
-     else								      \
-       {								      \
-	 result = 0;							      \
-	 abort ();							      \
-       }								      \
-     result; })
+#define atomic_exchange_acq(mem, value)                                \
+  __atomic_val_bysize (__arch_exchange, int, mem, value, __ATOMIC_ACQUIRE)
+
+# define __arch_exchange_8_int(mem, newval, model)      \
+  (__arm_link_error (), (typeof (*mem)) 0)
+
+# define __arch_exchange_16_int(mem, newval, model)     \
+  (__arm_link_error (), (typeof (*mem)) 0)
+
+# define __arch_exchange_32_int(mem, newval, model)     \
+  __atomic_exchange_n (mem, newval, model)
+
+# define __arch_exchange_64_int(mem, newval, model)     \
+  (__arm_link_error (), (typeof (*mem)) 0)
 
 /* Atomic compare and exchange.  This sequence relies on the kernel to
    provide a compare and exchange operation which is atomic on the
@@ -67,29 +65,74 @@
 
 /* It doesn't matter what register is used for a_oldval2, but we must
    specify one to work around GCC PR rtl-optimization/21223.  Otherwise
-   it may cause a_oldval or a_tmp to be moved to a different register.  */
+   it may cause a_oldval or a_tmp to be moved to a different register.
 
-#define __arch_compare_and_exchange_val_32_acq(mem, newval, oldval) \
-  ({ register __typeof (oldval) a_oldval asm ("r0");			      \
-     register __typeof (oldval) a_newval asm ("r1") = (newval);		      \
-     register __typeof (mem) a_ptr asm ("r2") = (mem);			      \
-     register __typeof (oldval) a_tmp asm ("r3");			      \
-     register __typeof (oldval) a_oldval2 asm ("r4") = (oldval);	      \
+   We use the union trick rather than simply using __typeof (...) in the
+   declarations of A_OLDVAL et al because when NEWVAL or OLDVAL is of the
+   form *PTR and PTR has a 'volatile ... *' type, then __typeof (*PTR) has
+   a 'volatile ...' type and this triggers -Wvolatile-register-var to
+   complain about 'register volatile ... asm ("reg")'.
+
+   We use the same union trick in the declaration of A_PTR because when
+   MEM is of the from *PTR and PTR has a 'const ... *' type, then __typeof
+   (*PTR) has a 'const ...' type and this enables the compiler to substitute
+   the variable with its initializer in asm statements, which may cause the
+   corresponding operand to appear in a different register.  */
+#ifdef __thumb2__
+/* Thumb-2 has ldrex/strex.  However it does not have barrier instructions,
+   so we still need to use the kernel helper.  */
+# define __arch_compare_and_exchange_val_32_acq(mem, newval, oldval) \
+  ({ union { __typeof (mem) a; uint32_t v; } mem_arg = { .a = (mem) };       \
+     union { __typeof (oldval) a; uint32_t v; } oldval_arg = { .a = (oldval) };\
+     union { __typeof (newval) a; uint32_t v; } newval_arg = { .a = (newval) };\
+     register uint32_t a_oldval asm ("r0");				      \
+     register uint32_t a_newval asm ("r1") = newval_arg.v;		      \
+     register uint32_t a_ptr asm ("r2") = mem_arg.v;			      \
+     register uint32_t a_tmp asm ("r3");				      \
+     register uint32_t a_oldval2 asm ("r4") = oldval_arg.v;		      \
+     __asm__ __volatile__						      \
+	     ("0:\tldr\t%[tmp],[%[ptr]]\n\t"				      \
+	      "cmp\t%[tmp], %[old2]\n\t"				      \
+	      "bne\t1f\n\t"						      \
+	      "mov\t%[old], %[old2]\n\t"				      \
+	      "movw\t%[tmp], #0x0fc0\n\t"				      \
+	      "movt\t%[tmp], #0xffff\n\t"				      \
+	      "blx\t%[tmp]\n\t"						      \
+	      "bcc\t0b\n\t"						      \
+	      "mov\t%[tmp], %[old2]\n\t"				      \
+	      "1:"							      \
+	      : [old] "=&r" (a_oldval), [tmp] "=&r" (a_tmp)		      \
+	      : [new] "r" (a_newval), [ptr] "r" (a_ptr),		      \
+		[old2] "r" (a_oldval2)					      \
+	      : "ip", "lr", "cc", "memory");				      \
+     (__typeof (oldval)) a_tmp; })
+#else
+# define __arch_compare_and_exchange_val_32_acq(mem, newval, oldval) \
+  ({ union { __typeof (mem) a; uint32_t v; } mem_arg = { .a = (mem) };       \
+     union { __typeof (oldval) a; uint32_t v; } oldval_arg = { .a = (oldval) };\
+     union { __typeof (newval) a; uint32_t v; } newval_arg = { .a = (newval) };\
+     register uint32_t a_oldval asm ("r0");				      \
+     register uint32_t a_newval asm ("r1") = newval_arg.v;		      \
+     register uint32_t a_ptr asm ("r2") = mem_arg.v;			      \
+     register uint32_t a_tmp asm ("r3");				      \
+     register uint32_t a_oldval2 asm ("r4") = oldval_arg.v;		      \
      __asm__ __volatile__						      \
-	     ("0:\tldr\t%1,[%3]\n\t"					      \
-	      "cmp\t%1, %4\n\t"						      \
+	     ("0:\tldr\t%[tmp],[%[ptr]]\n\t"				      \
+	      "cmp\t%[tmp], %[old2]\n\t"				      \
 	      "bne\t1f\n\t"						      \
-	      "mov\t%0, %4\n\t"						      \
-	      "mov\t%1, #0xffff0fff\n\t"				      \
+	      "mov\t%[old], %[old2]\n\t"				      \
+	      "mov\t%[tmp], #0xffff0fff\n\t"				      \
 	      "mov\tlr, pc\n\t"						      \
-	      "add\tpc, %1, #(0xffff0fc0 - 0xffff0fff)\n\t"		      \
+	      "add\tpc, %[tmp], #(0xffff0fc0 - 0xffff0fff)\n\t"		      \
 	      "bcc\t0b\n\t"						      \
-	      "mov\t%1, %4\n\t"						      \
+	      "mov\t%[tmp], %[old2]\n\t"				      \
 	      "1:"							      \
-	      : "=&r" (a_oldval), "=&r" (a_tmp)				      \
-	      : "r" (a_newval), "r" (a_ptr), "r" (a_oldval2)		      \
+	      : [old] "=&r" (a_oldval), [tmp] "=&r" (a_tmp)		      \
+	      : [new] "r" (a_newval), [ptr] "r" (a_ptr),		      \
+		[old2] "r" (a_oldval2)					      \
 	      : "ip", "lr", "cc", "memory");				      \
-     a_tmp; })
+     (__typeof (oldval)) a_tmp; })
+#endif
 
 #define __arch_compare_and_exchange_val_64_acq(mem, newval, oldval) \
   ({ __arm_link_error (); oldval; })
