From ce30a6a4ff1bbc8348dba36383013864667093ca Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Ole=20Andr=C3=A9=20Vadla=20Ravn=C3=A5s?= <oleavr@gmail.com>
Date: Mon, 12 Sep 2022 15:05:39 +0000
Subject: [PATCH 1/2] MIPS: Backport atomics

---
 sysdeps/mips/bits/atomic.h | 266 +++++++++++--------------------------
 1 file changed, 74 insertions(+), 192 deletions(-)

diff --git a/sysdeps/mips/bits/atomic.h b/sysdeps/mips/bits/atomic.h
index 167d9a5..37eb486 100644
--- a/sysdeps/mips/bits/atomic.h
+++ b/sysdeps/mips/bits/atomic.h
@@ -53,251 +53,133 @@ typedef uintmax_t uatomic_max_t;
 #define MIPS_SYNC_STR_1(X) MIPS_SYNC_STR_2(X)
 #define MIPS_SYNC_STR MIPS_SYNC_STR_1(MIPS_SYNC)
 
-/* Compare and exchange.  For all of the "xxx" routines, we expect a
-   "__prev" and a "__cmp" variable to be provided by the enclosing scope,
-   in which values are returned.  */
-
-#define __arch_compare_and_exchange_xxx_8_int(mem, newval, oldval, rel, acq) \
-  (abort (), __prev = __cmp = 0)
-
-#define __arch_compare_and_exchange_xxx_16_int(mem, newval, oldval, rel, acq) \
-  (abort (), __prev = __cmp = 0)
-
-#define __arch_compare_and_exchange_xxx_32_int(mem, newval, oldval, rel, acq) \
-     __asm__ __volatile__ (						      \
-     ".set	push\n\t"						      \
-     MIPS_PUSH_MIPS2							      \
-     rel	"\n"							      \
-     "1:\t"								      \
-     "ll	%0,%4\n\t"						      \
-     "move	%1,$0\n\t"						      \
-     "bne	%0,%2,2f\n\t"						      \
-     "move	%1,%3\n\t"						      \
-     "sc	%1,%4\n\t"						      \
-     "beqz	%1,1b\n"						      \
-     acq	"\n\t"							      \
-     ".set	pop\n"							      \
-     "2:\n\t"								      \
-	      : "=&r" (__prev), "=&r" (__cmp)				      \
-	      : "r" (oldval), "r" (newval), "m" (*mem)			      \
-	      : "memory")
+/* Compare and exchange.
+   For all "bool" routines, we return FALSE if exchange succesful.  */
 
-#if _MIPS_SIM == _ABIO32
-/* We can't do an atomic 64-bit operation in O32.  */
-#define __arch_compare_and_exchange_xxx_64_int(mem, newval, oldval, rel, acq) \
-  (abort (), __prev = __cmp = 0)
-#else
-#define __arch_compare_and_exchange_xxx_64_int(mem, newval, oldval, rel, acq) \
-     __asm__ __volatile__ ("\n"						      \
-     ".set	push\n\t"						      \
-     MIPS_PUSH_MIPS2							      \
-     rel	"\n"							      \
-     "1:\t"								      \
-     "lld	%0,%4\n\t"						      \
-     "move	%1,$0\n\t"						      \
-     "bne	%0,%2,2f\n\t"						      \
-     "move	%1,%3\n\t"						      \
-     "scd	%1,%4\n\t"						      \
-     "beqz	%1,1b\n"						      \
-     acq	"\n\t"							      \
-     ".set	pop\n"							      \
-     "2:\n\t"								      \
-	      : "=&r" (__prev), "=&r" (__cmp)				      \
-	      : "r" (oldval), "r" (newval), "m" (*mem)			      \
-	      : "memory")
-#endif
-
-/* For all "bool" routines, we return FALSE if exchange succesful.  */
-
-#define __arch_compare_and_exchange_bool_8_int(mem, new, old, rel, acq)	\
-({ typeof (*mem) __prev; int __cmp;					\
-   __arch_compare_and_exchange_xxx_8_int(mem, new, old, rel, acq);	\
-   !__cmp; })
-
-#define __arch_compare_and_exchange_bool_16_int(mem, new, old, rel, acq) \
-({ typeof (*mem) __prev; int __cmp;					\
-   __arch_compare_and_exchange_xxx_16_int(mem, new, old, rel, acq);	\
-   !__cmp; })
-
-#define __arch_compare_and_exchange_bool_32_int(mem, new, old, rel, acq) \
-({ typeof (*mem) __prev; int __cmp;					\
-   __arch_compare_and_exchange_xxx_32_int(mem, new, old, rel, acq);	\
-   !__cmp; })
+#define __arch_compare_and_exchange_bool_8_int(mem, newval, oldval, model) \
+  (abort (), 0)
 
-#define __arch_compare_and_exchange_bool_64_int(mem, new, old, rel, acq) \
-({ typeof (*mem) __prev; int __cmp;					\
-   __arch_compare_and_exchange_xxx_64_int(mem, new, old, rel, acq);	\
-   !__cmp; })
+#define __arch_compare_and_exchange_bool_16_int(mem, newval, oldval, model) \
+  (abort (), 0)
 
-/* For all "val" routines, return the old value whether exchange
-   successful or not.  */
+#define __arch_compare_and_exchange_bool_32_int(mem, newval, oldval, model) \
+  ({									\
+    typeof (*mem) __oldval = (oldval);					\
+    !__atomic_compare_exchange_n (mem, (void *) &__oldval, newval, 0,	\
+				  model, __ATOMIC_RELAXED);		\
+  })
 
-#define __arch_compare_and_exchange_val_8_int(mem, new, old, rel, acq)	\
-({ typeof (*mem) __prev; int __cmp;					\
-   __arch_compare_and_exchange_xxx_8_int(mem, new, old, rel, acq);	\
-   (typeof (*mem))__prev; })
+#define __arch_compare_and_exchange_val_8_int(mem, newval, oldval, model) \
+  (abort (), (typeof(*mem)) 0)
 
-#define __arch_compare_and_exchange_val_16_int(mem, new, old, rel, acq) \
-({ typeof (*mem) __prev; int __cmp;					\
-   __arch_compare_and_exchange_xxx_16_int(mem, new, old, rel, acq);	\
-   (typeof (*mem))__prev; })
+#define __arch_compare_and_exchange_val_16_int(mem, newval, oldval, model) \
+  (abort (), (typeof(*mem)) 0)
 
-#define __arch_compare_and_exchange_val_32_int(mem, new, old, rel, acq) \
-({ typeof (*mem) __prev; int __cmp;					\
-   __arch_compare_and_exchange_xxx_32_int(mem, new, old, rel, acq);	\
-   (typeof (*mem))__prev; })
+#define __arch_compare_and_exchange_val_32_int(mem, newval, oldval, model) \
+  ({									\
+    typeof (*mem) __oldval = (oldval);					\
+    __atomic_compare_exchange_n (mem, (void *) &__oldval, newval, 0,	\
+				 model, __ATOMIC_RELAXED);		\
+    __oldval;								\
+  })
 
-#define __arch_compare_and_exchange_val_64_int(mem, new, old, rel, acq) \
-({ typeof (*mem) __prev; int __cmp;					\
-   __arch_compare_and_exchange_xxx_64_int(mem, new, old, rel, acq);	\
-   (typeof (*mem))__prev; })
+#if _MIPS_SIM == _ABIO32
+  /* We can't do an atomic 64-bit operation in O32.  */
+# define __arch_compare_and_exchange_bool_64_int(mem, newval, oldval, model) \
+  (abort (), 0)
+# define __arch_compare_and_exchange_val_64_int(mem, newval, oldval, model) \
+  (abort (), (typeof(*mem)) 0)
+#else
+# define __arch_compare_and_exchange_bool_64_int(mem, newval, oldval, model) \
+  __arch_compare_and_exchange_bool_32_int (mem, newval, oldval, model)
+# define __arch_compare_and_exchange_val_64_int(mem, newval, oldval, model) \
+  __arch_compare_and_exchange_val_32_int (mem, newval, oldval, model)
+#endif
 
 /* Compare and exchange with "acquire" semantics, ie barrier after.  */
 
 #define atomic_compare_and_exchange_bool_acq(mem, new, old)	\
   __atomic_bool_bysize (__arch_compare_and_exchange_bool, int,	\
-		        mem, new, old, "", MIPS_SYNC_STR)
+			mem, new, old, __ATOMIC_ACQUIRE)
 
 #define atomic_compare_and_exchange_val_acq(mem, new, old)	\
   __atomic_val_bysize (__arch_compare_and_exchange_val, int,	\
-		       mem, new, old, "", MIPS_SYNC_STR)
+		       mem, new, old, __ATOMIC_ACQUIRE)
 
 /* Compare and exchange with "release" semantics, ie barrier before.  */
 
-#define atomic_compare_and_exchange_bool_rel(mem, new, old)	\
-  __atomic_bool_bysize (__arch_compare_and_exchange_bool, int,	\
-		        mem, new, old, MIPS_SYNC_STR, "")
-
-#define atomic_compare_and_exchange_val_rel(mem, new, old)	\
-  __atomic_val_bysize (__arch_compare_and_exchange_val, int,	\
-		       mem, new, old, MIPS_SYNC_STR, "")
-
+#define atomic_compare_and_exchange_val_rel(mem, new, old)	 \
+  __atomic_val_bysize (__arch_compare_and_exchange_val, int,    \
+                       mem, new, old, __ATOMIC_RELEASE)
 
 
 /* Atomic exchange (without compare).  */
 
-#define __arch_exchange_xxx_8_int(mem, newval, rel, acq) \
-  (abort (), 0)
+#define __arch_exchange_8_int(mem, newval, model)	\
+  (abort (), (typeof(*mem)) 0)
 
-#define __arch_exchange_xxx_16_int(mem, newval, rel, acq) \
-  (abort (), 0)
+#define __arch_exchange_16_int(mem, newval, model)	\
+  (abort (), (typeof(*mem)) 0)
 
-#define __arch_exchange_xxx_32_int(mem, newval, rel, acq) \
-({ typeof (*mem) __prev; int __cmp;					      \
-     __asm__ __volatile__ ("\n"						      \
-     ".set	push\n\t"						      \
-     MIPS_PUSH_MIPS2							      \
-     rel	"\n"							      \
-     "1:\t"								      \
-     "ll	%0,%3\n\t"						      \
-     "move	%1,%2\n\t"						      \
-     "sc	%1,%3\n\t"						      \
-     "beqz	%1,1b\n"						      \
-     acq	"\n\t"							      \
-     ".set	pop\n"							      \
-     "2:\n\t"								      \
-	      : "=&r" (__prev), "=&r" (__cmp)				      \
-	      : "r" (newval), "m" (*mem)				      \
-	      : "memory");						      \
-  __prev; })
+#define __arch_exchange_32_int(mem, newval, model)	\
+  __atomic_exchange_n (mem, newval, model)
 
 #if _MIPS_SIM == _ABIO32
 /* We can't do an atomic 64-bit operation in O32.  */
-#define __arch_exchange_xxx_64_int(mem, newval, rel, acq) \
-  (abort (), 0)
+# define __arch_exchange_64_int(mem, newval, model)	\
+  (abort (), (typeof(*mem)) 0)
 #else
-#define __arch_exchange_xxx_64_int(mem, newval, rel, acq) \
-({ typeof (*mem) __prev; int __cmp;					      \
-     __asm__ __volatile__ ("\n"						      \
-     ".set	push\n\t"						      \
-     MIPS_PUSH_MIPS2							      \
-     rel	"\n"							      \
-     "1:\n"								      \
-     "lld	%0,%3\n\t"						      \
-     "move	%1,%2\n\t"						      \
-     "scd	%1,%3\n\t"						      \
-     "beqz	%1,1b\n"						      \
-     acq	"\n\t"							      \
-     ".set	pop\n"							      \
-     "2:\n\t"								      \
-	      : "=&r" (__prev), "=&r" (__cmp)				      \
-	      : "r" (newval), "m" (*mem)				      \
-	      : "memory");						      \
-  __prev; })
+# define __arch_exchange_64_int(mem, newval, model)	\
+  __atomic_exchange_n (mem, newval, model)
 #endif
 
-#define atomic_exchange_acq(mem, value) \
-  __atomic_val_bysize (__arch_exchange_xxx, int, mem, value, "", MIPS_SYNC_STR)
+#define atomic_exchange_acq(mem, value)				\
+  __atomic_val_bysize (__arch_exchange, int, mem, value, __ATOMIC_ACQUIRE)
 
-#define atomic_exchange_rel(mem, value) \
-  __atomic_val_bysize (__arch_exchange_xxx, int, mem, value, MIPS_SYNC_STR, "")
+#define atomic_exchange_rel(mem, value)				\
+  __atomic_val_bysize (__arch_exchange, int, mem, value, __ATOMIC_RELEASE)
 
 
 /* Atomically add value and return the previous (unincremented) value.  */
 
-#define __arch_exchange_and_add_8_int(mem, newval, rel, acq) \
+#define __arch_exchange_and_add_8_int(mem, value, model)	\
   (abort (), (typeof(*mem)) 0)
 
-#define __arch_exchange_and_add_16_int(mem, newval, rel, acq) \
+#define __arch_exchange_and_add_16_int(mem, value, model)	\
   (abort (), (typeof(*mem)) 0)
 
-#define __arch_exchange_and_add_32_int(mem, value, rel, acq) \
-({ typeof (*mem) __prev; int __cmp;					      \
-     __asm__ __volatile__ ("\n"						      \
-     ".set	push\n\t"						      \
-     MIPS_PUSH_MIPS2							      \
-     rel	"\n"							      \
-     "1:\t"								      \
-     "ll	%0,%3\n\t"						      \
-     "addu	%1,%0,%2\n\t"						      \
-     "sc	%1,%3\n\t"						      \
-     "beqz	%1,1b\n"						      \
-     acq	"\n\t"							      \
-     ".set	pop\n"							      \
-     "2:\n\t"								      \
-	      : "=&r" (__prev), "=&r" (__cmp)				      \
-	      : "r" (value), "m" (*mem)					      \
-	      : "memory");						      \
-  __prev; })
+#define __arch_exchange_and_add_32_int(mem, value, model)	\
+  __atomic_fetch_add (mem, value, model)
 
 #if _MIPS_SIM == _ABIO32
 /* We can't do an atomic 64-bit operation in O32.  */
-#define __arch_exchange_and_add_64_int(mem, value, rel, acq) \
+# define __arch_exchange_and_add_64_int(mem, value, model)	\
   (abort (), (typeof(*mem)) 0)
 #else
-#define __arch_exchange_and_add_64_int(mem, value, rel, acq) \
-({ typeof (*mem) __prev; int __cmp;					      \
-     __asm__ __volatile__ (						      \
-     ".set	push\n\t"						      \
-     MIPS_PUSH_MIPS2							      \
-     rel	"\n"							      \
-     "1:\t"								      \
-     "lld	%0,%3\n\t"						      \
-     "daddu	%1,%0,%2\n\t"						      \
-     "scd	%1,%3\n\t"						      \
-     "beqz	%1,1b\n"						      \
-     acq	"\n\t"							      \
-     ".set	pop\n"							      \
-     "2:\n\t"								      \
-	      : "=&r" (__prev), "=&r" (__cmp)				      \
-	      : "r" (value), "m" (*mem)					      \
-	      : "memory");						      \
-  __prev; })
+# define __arch_exchange_and_add_64_int(mem, value, model)	\
+  __atomic_fetch_add (mem, value, model)
 #endif
 
-/* ??? Barrier semantics for atomic_exchange_and_add appear to be 
-   undefined.  Use full barrier for now, as that's safe.  */
-#define atomic_exchange_and_add(mem, value) \
-  __atomic_val_bysize (__arch_exchange_and_add, int, mem, value,	      \
-		       MIPS_SYNC_STR, MIPS_SYNC_STR)
+#define atomic_exchange_and_add_acq(mem, value)			\
+  __atomic_val_bysize (__arch_exchange_and_add, int, mem, value,	\
+		       __ATOMIC_ACQUIRE)
+
+#define atomic_exchange_and_add_rel(mem, value)			\
+  __atomic_val_bysize (__arch_exchange_and_add, int, mem, value,	\
+		       __ATOMIC_RELEASE)
 
 /* TODO: More atomic operations could be implemented efficiently; only the
    basic requirements are done.  */
 
-#define atomic_full_barrier() \
+#ifdef __mips16
+# define atomic_full_barrier() __sync_synchronize ()
+
+#else /* !__mips16 */
+# define atomic_full_barrier() \
   __asm__ __volatile__ (".set push\n\t"					      \
 			MIPS_PUSH_MIPS2					      \
 			MIPS_SYNC_STR "\n\t"				      \
 			".set pop" : : : "memory")
+#endif /* !__mips16 */
 
 #endif /* bits/atomic.h */
-- 
2.34.1

